{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNT28Cn9y7wAFwTl9oRgKGB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahalaxmy/NLP/blob/main/creating_dictionary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnKq-uB2gGcb",
        "outputId": "821dba6e-ffb8-42a7-e133-f7686598bdc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['scikit-learn', 'is', 'largely', 'written', 'in', 'Python', ',', 'and', 'uses', 'NumPy', 'extensively', 'for', 'high-performance', 'linear', 'algebra', 'and', 'array', 'operations', '.', 'Furthermore', ',', 'some', 'core', 'algorithms', 'are', 'written', 'in', 'Cython', 'to', 'improve', 'performance', '.', 'Support', 'vector', 'machines', 'are', 'implemented', 'by', 'a', 'Cython', 'wrapper', 'around', 'LIBSVM', ';', 'logistic', 'regression', 'and', 'linear', 'support', 'vector', 'machines', 'by', 'a', 'similar', 'wrapper', 'around', 'LIBLINEAR', '.', 'In', 'such', 'cases', ',', 'extending', 'these', 'methods', 'with', 'Python', 'may', 'not', 'be', 'possible.scikit-learn', 'integrates', 'well', 'with', 'many', 'other', 'Python', 'libraries', ',', 'such', 'as', 'Matplotlib', 'and', 'plotly', 'for', 'plotting', ',', 'NumPy', 'for', 'array', 'vectorization', ',', 'Pandas', 'dataframes', ',', 'SciPy', ',', 'and', 'many', 'more', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "import nltk.data\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "\n",
        "text = \"scikit-learn is largely written in Python, and uses NumPy extensively for high-performance linear algebra and array operations. Furthermore, some core algorithms are written in Cython to improve performance. Support vector machines are implemented by a Cython wrapper around LIBSVM; logistic regression and linear support vector machines by a similar wrapper around LIBLINEAR. In such cases, extending these methods with Python may not be possible.scikit-learn integrates well with many other Python libraries, such as Matplotlib and plotly for plotting, NumPy for array vectorization, Pandas dataframes, SciPy, and many more.\"\n",
        "\n",
        "\n",
        "tokens = word_tokenize(text)\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J86p3SCThGZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPLc5N3agtGZ",
        "outputId": "61b75383-9489-4bbc-d24e-d14f12b6e5f1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{',',\n",
              " '.',\n",
              " ';',\n",
              " 'Cython',\n",
              " 'Furthermore',\n",
              " 'In',\n",
              " 'LIBLINEAR',\n",
              " 'LIBSVM',\n",
              " 'Matplotlib',\n",
              " 'NumPy',\n",
              " 'Pandas',\n",
              " 'Python',\n",
              " 'SciPy',\n",
              " 'Support',\n",
              " 'a',\n",
              " 'algebra',\n",
              " 'algorithms',\n",
              " 'and',\n",
              " 'are',\n",
              " 'around',\n",
              " 'array',\n",
              " 'as',\n",
              " 'be',\n",
              " 'by',\n",
              " 'cases',\n",
              " 'core',\n",
              " 'dataframes',\n",
              " 'extending',\n",
              " 'extensively',\n",
              " 'for',\n",
              " 'high-performance',\n",
              " 'implemented',\n",
              " 'improve',\n",
              " 'in',\n",
              " 'integrates',\n",
              " 'is',\n",
              " 'largely',\n",
              " 'libraries',\n",
              " 'linear',\n",
              " 'logistic',\n",
              " 'machines',\n",
              " 'many',\n",
              " 'may',\n",
              " 'methods',\n",
              " 'more',\n",
              " 'not',\n",
              " 'operations',\n",
              " 'other',\n",
              " 'performance',\n",
              " 'plotly',\n",
              " 'plotting',\n",
              " 'possible.scikit-learn',\n",
              " 'regression',\n",
              " 'scikit-learn',\n",
              " 'similar',\n",
              " 'some',\n",
              " 'such',\n",
              " 'support',\n",
              " 'these',\n",
              " 'to',\n",
              " 'uses',\n",
              " 'vector',\n",
              " 'vectorization',\n",
              " 'well',\n",
              " 'with',\n",
              " 'wrapper',\n",
              " 'written'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "import nltk.data\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "\n",
        "text1 =  \"We present iNLTK, an open-source NLP library consisting of pre-trained language models and out-of-the-box support for Data Augmentation, Textual Similarity, Sentence Embeddings, Word Embeddings, Tokenization and Text Generation in 13 Indic Languages. By using pre-trained models from iNLTK for text classification on publicly available datasets, we significantly outperform previously reported results. On these datasets, we also show that by using pre-trained models and data augmentation from iNLTK, we can achieve more than 95% of the previous best performance by using less than 10% of the training data. iNLTK is already being widely used by the community and has 40,000+ downloads, 600+ stars and 100+ forks on GitHub. The library is available at https://github.com/goru001/inltk;\"\n",
        "\n",
        "\n",
        "\n",
        "tokens1 = word_tokenize(text1)\n",
        "print(tokens1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QaiISeOgtJJ",
        "outputId": "e5c65d86-0e5b-4ce9-8cd4-d6bffe292649"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['We', 'present', 'iNLTK', ',', 'an', 'open-source', 'NLP', 'library', 'consisting', 'of', 'pre-trained', 'language', 'models', 'and', 'out-of-the-box', 'support', 'for', 'Data', 'Augmentation', ',', 'Textual', 'Similarity', ',', 'Sentence', 'Embeddings', ',', 'Word', 'Embeddings', ',', 'Tokenization', 'and', 'Text', 'Generation', 'in', '13', 'Indic', 'Languages', '.', 'By', 'using', 'pre-trained', 'models', 'from', 'iNLTK', 'for', 'text', 'classification', 'on', 'publicly', 'available', 'datasets', ',', 'we', 'significantly', 'outperform', 'previously', 'reported', 'results', '.', 'On', 'these', 'datasets', ',', 'we', 'also', 'show', 'that', 'by', 'using', 'pre-trained', 'models', 'and', 'data', 'augmentation', 'from', 'iNLTK', ',', 'we', 'can', 'achieve', 'more', 'than', '95', '%', 'of', 'the', 'previous', 'best', 'performance', 'by', 'using', 'less', 'than', '10', '%', 'of', 'the', 'training', 'data', '.', 'iNLTK', 'is', 'already', 'being', 'widely', 'used', 'by', 'the', 'community', 'and', 'has', '40,000+', 'downloads', ',', '600+', 'stars', 'and', '100+', 'forks', 'on', 'GitHub', '.', 'The', 'library', 'is', 'available', 'at', 'https', ':', '//github.com/goru001/inltk', ';']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "import nltk.data\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "\n",
        "text2 = \"The Natural Language Toolkit, or more commonly NLTK, is a suite of libraries and programs for symbolic and statistical natural language processing NLP for English written in the Python programming language. It supports classification, tokenization, stemming, tagging, parsing, and semantic reasoning functionalities. It was developed by Steven Bird and Edward Loper in the Department of Computer and Information Science at the University of Pennsylvania.NLTK includes graphical demonstrations and sample data. It is accompanied by a book that explains the underlying concepts behind the language processing tasks supported by the toolkit, plus a cookbook.\"\n",
        "tokens2 = word_tokenize(text2)\n",
        "print(tokens2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxUuGZdyhHXk",
        "outputId": "606672aa-c7eb-44cb-8b40-0f1a0c55a443"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'Natural', 'Language', 'Toolkit', ',', 'or', 'more', 'commonly', 'NLTK', ',', 'is', 'a', 'suite', 'of', 'libraries', 'and', 'programs', 'for', 'symbolic', 'and', 'statistical', 'natural', 'language', 'processing', 'NLP', 'for', 'English', 'written', 'in', 'the', 'Python', 'programming', 'language', '.', 'It', 'supports', 'classification', ',', 'tokenization', ',', 'stemming', ',', 'tagging', ',', 'parsing', ',', 'and', 'semantic', 'reasoning', 'functionalities', '.', 'It', 'was', 'developed', 'by', 'Steven', 'Bird', 'and', 'Edward', 'Loper', 'in', 'the', 'Department', 'of', 'Computer', 'and', 'Information', 'Science', 'at', 'the', 'University', 'of', 'Pennsylvania.NLTK', 'includes', 'graphical', 'demonstrations', 'and', 'sample', 'data', '.', 'It', 'is', 'accompanied', 'by', 'a', 'book', 'that', 'explains', 'the', 'underlying', 'concepts', 'behind', 'the', 'language', 'processing', 'tasks', 'supported', 'by', 'the', 'toolkit', ',', 'plus', 'a', 'cookbook', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list4=tokens+tokens1+tokens2\n",
        "list4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32A5tPcJhWTa",
        "outputId": "9140b2c5-6964-4598-c19b-a5f320974e13"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['scikit-learn',\n",
              " 'is',\n",
              " 'largely',\n",
              " 'written',\n",
              " 'in',\n",
              " 'Python',\n",
              " ',',\n",
              " 'and',\n",
              " 'uses',\n",
              " 'NumPy',\n",
              " 'extensively',\n",
              " 'for',\n",
              " 'high-performance',\n",
              " 'linear',\n",
              " 'algebra',\n",
              " 'and',\n",
              " 'array',\n",
              " 'operations',\n",
              " '.',\n",
              " 'Furthermore',\n",
              " ',',\n",
              " 'some',\n",
              " 'core',\n",
              " 'algorithms',\n",
              " 'are',\n",
              " 'written',\n",
              " 'in',\n",
              " 'Cython',\n",
              " 'to',\n",
              " 'improve',\n",
              " 'performance',\n",
              " '.',\n",
              " 'Support',\n",
              " 'vector',\n",
              " 'machines',\n",
              " 'are',\n",
              " 'implemented',\n",
              " 'by',\n",
              " 'a',\n",
              " 'Cython',\n",
              " 'wrapper',\n",
              " 'around',\n",
              " 'LIBSVM',\n",
              " ';',\n",
              " 'logistic',\n",
              " 'regression',\n",
              " 'and',\n",
              " 'linear',\n",
              " 'support',\n",
              " 'vector',\n",
              " 'machines',\n",
              " 'by',\n",
              " 'a',\n",
              " 'similar',\n",
              " 'wrapper',\n",
              " 'around',\n",
              " 'LIBLINEAR',\n",
              " '.',\n",
              " 'In',\n",
              " 'such',\n",
              " 'cases',\n",
              " ',',\n",
              " 'extending',\n",
              " 'these',\n",
              " 'methods',\n",
              " 'with',\n",
              " 'Python',\n",
              " 'may',\n",
              " 'not',\n",
              " 'be',\n",
              " 'possible.scikit-learn',\n",
              " 'integrates',\n",
              " 'well',\n",
              " 'with',\n",
              " 'many',\n",
              " 'other',\n",
              " 'Python',\n",
              " 'libraries',\n",
              " ',',\n",
              " 'such',\n",
              " 'as',\n",
              " 'Matplotlib',\n",
              " 'and',\n",
              " 'plotly',\n",
              " 'for',\n",
              " 'plotting',\n",
              " ',',\n",
              " 'NumPy',\n",
              " 'for',\n",
              " 'array',\n",
              " 'vectorization',\n",
              " ',',\n",
              " 'Pandas',\n",
              " 'dataframes',\n",
              " ',',\n",
              " 'SciPy',\n",
              " ',',\n",
              " 'and',\n",
              " 'many',\n",
              " 'more',\n",
              " '.',\n",
              " 'We',\n",
              " 'present',\n",
              " 'iNLTK',\n",
              " ',',\n",
              " 'an',\n",
              " 'open-source',\n",
              " 'NLP',\n",
              " 'library',\n",
              " 'consisting',\n",
              " 'of',\n",
              " 'pre-trained',\n",
              " 'language',\n",
              " 'models',\n",
              " 'and',\n",
              " 'out-of-the-box',\n",
              " 'support',\n",
              " 'for',\n",
              " 'Data',\n",
              " 'Augmentation',\n",
              " ',',\n",
              " 'Textual',\n",
              " 'Similarity',\n",
              " ',',\n",
              " 'Sentence',\n",
              " 'Embeddings',\n",
              " ',',\n",
              " 'Word',\n",
              " 'Embeddings',\n",
              " ',',\n",
              " 'Tokenization',\n",
              " 'and',\n",
              " 'Text',\n",
              " 'Generation',\n",
              " 'in',\n",
              " '13',\n",
              " 'Indic',\n",
              " 'Languages',\n",
              " '.',\n",
              " 'By',\n",
              " 'using',\n",
              " 'pre-trained',\n",
              " 'models',\n",
              " 'from',\n",
              " 'iNLTK',\n",
              " 'for',\n",
              " 'text',\n",
              " 'classification',\n",
              " 'on',\n",
              " 'publicly',\n",
              " 'available',\n",
              " 'datasets',\n",
              " ',',\n",
              " 'we',\n",
              " 'significantly',\n",
              " 'outperform',\n",
              " 'previously',\n",
              " 'reported',\n",
              " 'results',\n",
              " '.',\n",
              " 'On',\n",
              " 'these',\n",
              " 'datasets',\n",
              " ',',\n",
              " 'we',\n",
              " 'also',\n",
              " 'show',\n",
              " 'that',\n",
              " 'by',\n",
              " 'using',\n",
              " 'pre-trained',\n",
              " 'models',\n",
              " 'and',\n",
              " 'data',\n",
              " 'augmentation',\n",
              " 'from',\n",
              " 'iNLTK',\n",
              " ',',\n",
              " 'we',\n",
              " 'can',\n",
              " 'achieve',\n",
              " 'more',\n",
              " 'than',\n",
              " '95',\n",
              " '%',\n",
              " 'of',\n",
              " 'the',\n",
              " 'previous',\n",
              " 'best',\n",
              " 'performance',\n",
              " 'by',\n",
              " 'using',\n",
              " 'less',\n",
              " 'than',\n",
              " '10',\n",
              " '%',\n",
              " 'of',\n",
              " 'the',\n",
              " 'training',\n",
              " 'data',\n",
              " '.',\n",
              " 'iNLTK',\n",
              " 'is',\n",
              " 'already',\n",
              " 'being',\n",
              " 'widely',\n",
              " 'used',\n",
              " 'by',\n",
              " 'the',\n",
              " 'community',\n",
              " 'and',\n",
              " 'has',\n",
              " '40,000+',\n",
              " 'downloads',\n",
              " ',',\n",
              " '600+',\n",
              " 'stars',\n",
              " 'and',\n",
              " '100+',\n",
              " 'forks',\n",
              " 'on',\n",
              " 'GitHub',\n",
              " '.',\n",
              " 'The',\n",
              " 'library',\n",
              " 'is',\n",
              " 'available',\n",
              " 'at',\n",
              " 'https',\n",
              " ':',\n",
              " '//github.com/goru001/inltk',\n",
              " ';',\n",
              " 'The',\n",
              " 'Natural',\n",
              " 'Language',\n",
              " 'Toolkit',\n",
              " ',',\n",
              " 'or',\n",
              " 'more',\n",
              " 'commonly',\n",
              " 'NLTK',\n",
              " ',',\n",
              " 'is',\n",
              " 'a',\n",
              " 'suite',\n",
              " 'of',\n",
              " 'libraries',\n",
              " 'and',\n",
              " 'programs',\n",
              " 'for',\n",
              " 'symbolic',\n",
              " 'and',\n",
              " 'statistical',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'NLP',\n",
              " 'for',\n",
              " 'English',\n",
              " 'written',\n",
              " 'in',\n",
              " 'the',\n",
              " 'Python',\n",
              " 'programming',\n",
              " 'language',\n",
              " '.',\n",
              " 'It',\n",
              " 'supports',\n",
              " 'classification',\n",
              " ',',\n",
              " 'tokenization',\n",
              " ',',\n",
              " 'stemming',\n",
              " ',',\n",
              " 'tagging',\n",
              " ',',\n",
              " 'parsing',\n",
              " ',',\n",
              " 'and',\n",
              " 'semantic',\n",
              " 'reasoning',\n",
              " 'functionalities',\n",
              " '.',\n",
              " 'It',\n",
              " 'was',\n",
              " 'developed',\n",
              " 'by',\n",
              " 'Steven',\n",
              " 'Bird',\n",
              " 'and',\n",
              " 'Edward',\n",
              " 'Loper',\n",
              " 'in',\n",
              " 'the',\n",
              " 'Department',\n",
              " 'of',\n",
              " 'Computer',\n",
              " 'and',\n",
              " 'Information',\n",
              " 'Science',\n",
              " 'at',\n",
              " 'the',\n",
              " 'University',\n",
              " 'of',\n",
              " 'Pennsylvania.NLTK',\n",
              " 'includes',\n",
              " 'graphical',\n",
              " 'demonstrations',\n",
              " 'and',\n",
              " 'sample',\n",
              " 'data',\n",
              " '.',\n",
              " 'It',\n",
              " 'is',\n",
              " 'accompanied',\n",
              " 'by',\n",
              " 'a',\n",
              " 'book',\n",
              " 'that',\n",
              " 'explains',\n",
              " 'the',\n",
              " 'underlying',\n",
              " 'concepts',\n",
              " 'behind',\n",
              " 'the',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'tasks',\n",
              " 'supported',\n",
              " 'by',\n",
              " 'the',\n",
              " 'toolkit',\n",
              " ',',\n",
              " 'plus',\n",
              " 'a',\n",
              " 'cookbook',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set(list4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKX3t-d3h_jF",
        "outputId": "53b7f0b9-b37c-4f63-c9b9-a3eabe73363d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'%',\n",
              " ',',\n",
              " '.',\n",
              " '//github.com/goru001/inltk',\n",
              " '10',\n",
              " '100+',\n",
              " '13',\n",
              " '40,000+',\n",
              " '600+',\n",
              " '95',\n",
              " ':',\n",
              " ';',\n",
              " 'Augmentation',\n",
              " 'Bird',\n",
              " 'By',\n",
              " 'Computer',\n",
              " 'Cython',\n",
              " 'Data',\n",
              " 'Department',\n",
              " 'Edward',\n",
              " 'Embeddings',\n",
              " 'English',\n",
              " 'Furthermore',\n",
              " 'Generation',\n",
              " 'GitHub',\n",
              " 'In',\n",
              " 'Indic',\n",
              " 'Information',\n",
              " 'It',\n",
              " 'LIBLINEAR',\n",
              " 'LIBSVM',\n",
              " 'Language',\n",
              " 'Languages',\n",
              " 'Loper',\n",
              " 'Matplotlib',\n",
              " 'NLP',\n",
              " 'NLTK',\n",
              " 'Natural',\n",
              " 'NumPy',\n",
              " 'On',\n",
              " 'Pandas',\n",
              " 'Pennsylvania.NLTK',\n",
              " 'Python',\n",
              " 'SciPy',\n",
              " 'Science',\n",
              " 'Sentence',\n",
              " 'Similarity',\n",
              " 'Steven',\n",
              " 'Support',\n",
              " 'Text',\n",
              " 'Textual',\n",
              " 'The',\n",
              " 'Tokenization',\n",
              " 'Toolkit',\n",
              " 'University',\n",
              " 'We',\n",
              " 'Word',\n",
              " 'a',\n",
              " 'accompanied',\n",
              " 'achieve',\n",
              " 'algebra',\n",
              " 'algorithms',\n",
              " 'already',\n",
              " 'also',\n",
              " 'an',\n",
              " 'and',\n",
              " 'are',\n",
              " 'around',\n",
              " 'array',\n",
              " 'as',\n",
              " 'at',\n",
              " 'augmentation',\n",
              " 'available',\n",
              " 'be',\n",
              " 'behind',\n",
              " 'being',\n",
              " 'best',\n",
              " 'book',\n",
              " 'by',\n",
              " 'can',\n",
              " 'cases',\n",
              " 'classification',\n",
              " 'commonly',\n",
              " 'community',\n",
              " 'concepts',\n",
              " 'consisting',\n",
              " 'cookbook',\n",
              " 'core',\n",
              " 'data',\n",
              " 'dataframes',\n",
              " 'datasets',\n",
              " 'demonstrations',\n",
              " 'developed',\n",
              " 'downloads',\n",
              " 'explains',\n",
              " 'extending',\n",
              " 'extensively',\n",
              " 'for',\n",
              " 'forks',\n",
              " 'from',\n",
              " 'functionalities',\n",
              " 'graphical',\n",
              " 'has',\n",
              " 'high-performance',\n",
              " 'https',\n",
              " 'iNLTK',\n",
              " 'implemented',\n",
              " 'improve',\n",
              " 'in',\n",
              " 'includes',\n",
              " 'integrates',\n",
              " 'is',\n",
              " 'language',\n",
              " 'largely',\n",
              " 'less',\n",
              " 'libraries',\n",
              " 'library',\n",
              " 'linear',\n",
              " 'logistic',\n",
              " 'machines',\n",
              " 'many',\n",
              " 'may',\n",
              " 'methods',\n",
              " 'models',\n",
              " 'more',\n",
              " 'natural',\n",
              " 'not',\n",
              " 'of',\n",
              " 'on',\n",
              " 'open-source',\n",
              " 'operations',\n",
              " 'or',\n",
              " 'other',\n",
              " 'out-of-the-box',\n",
              " 'outperform',\n",
              " 'parsing',\n",
              " 'performance',\n",
              " 'plotly',\n",
              " 'plotting',\n",
              " 'plus',\n",
              " 'possible.scikit-learn',\n",
              " 'pre-trained',\n",
              " 'present',\n",
              " 'previous',\n",
              " 'previously',\n",
              " 'processing',\n",
              " 'programming',\n",
              " 'programs',\n",
              " 'publicly',\n",
              " 'reasoning',\n",
              " 'regression',\n",
              " 'reported',\n",
              " 'results',\n",
              " 'sample',\n",
              " 'scikit-learn',\n",
              " 'semantic',\n",
              " 'show',\n",
              " 'significantly',\n",
              " 'similar',\n",
              " 'some',\n",
              " 'stars',\n",
              " 'statistical',\n",
              " 'stemming',\n",
              " 'such',\n",
              " 'suite',\n",
              " 'support',\n",
              " 'supported',\n",
              " 'supports',\n",
              " 'symbolic',\n",
              " 'tagging',\n",
              " 'tasks',\n",
              " 'text',\n",
              " 'than',\n",
              " 'that',\n",
              " 'the',\n",
              " 'these',\n",
              " 'to',\n",
              " 'tokenization',\n",
              " 'toolkit',\n",
              " 'training',\n",
              " 'underlying',\n",
              " 'used',\n",
              " 'uses',\n",
              " 'using',\n",
              " 'vector',\n",
              " 'vectorization',\n",
              " 'was',\n",
              " 'we',\n",
              " 'well',\n",
              " 'widely',\n",
              " 'with',\n",
              " 'wrapper',\n",
              " 'written'}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}